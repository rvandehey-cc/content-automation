#!/usr/bin/env node
/**
 * @fileoverview CLI for running HTML scraper independently
 * @author Ryan Vandehey
 * @version 1.0.0
 */

import { HTMLScraperService } from '../core/scraper.js';
import { handleError } from '../utils/errors.js';

/**
 * Main function to run HTML scraper
 */
async function main() {
  try {
    console.log('ğŸŒ HTML SCRAPER');
    console.log('='.repeat(60));
    console.log('');
    
    // Initialize scraper service
    const scraperService = new HTMLScraperService();
    
    // Run scraping
    const results = await scraperService.scrapeUrls();
    
    console.log('\nâœ… Scraping complete!');
    console.log(`ğŸ“Š Scraped ${results.successful} URL(s) successfully`);
    
    if (results.failed > 0) {
      console.log(`âš ï¸  ${results.failed} URL(s) had errors`);
    }
    
    process.exit(0);
    
  } catch (error) {
    const errorInfo = handleError(error);
    console.error(`\nâŒ ERROR: ${errorInfo.userMessage}`);
    console.error(`ğŸ’¡ ${errorInfo.suggestion}`);
    
    if (process.env.NODE_ENV === 'development') {
      console.error('\nğŸ“‹ Technical details:', errorInfo.technicalDetails);
    }
    
    process.exit(1);
  }
}

// Run main function
main();


